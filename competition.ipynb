{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad3f3d2-ddc1-4fee-ba7f-7f41a051dca5",
   "metadata": {},
   "source": [
    "\n",
    "从AI gallery中下载竞赛数据集至个人OBS桶中，[单击此处](https://developer.huaweicloud.com/develop/aigallery/dataset/detail?id=83c5a97d-05ec-4464-93ca-a621f3e03e82)进入数据集页面。\n",
    "\n",
    "要将您OBS桶中的数据文件加载到此notebook中，需将如下代码中 \"obs://***/data/\" 修改成您OBS桶名称和数据存储路径\n",
    "\n",
    "注意：此baseline notebook需要在“华北-北京四”区域运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b92e6-d830-48c7-b620-545de0cf64d7",
   "metadata": {},
   "source": [
    "此处为导入模型拷贝库，按Crtl+回车键即可运行框内的代码，运行完成后框左侧会显示一个序号，后面所有代码的运行方式都这样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9c6a7d-9f4f-427c-b433-a29e47d4e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v2.1.0.5d9c87c8-5d9c87c8\n",
      "\n",
      "INFO:root:Using OBS-Python-SDK-3.20.9.1\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28822b5-73e0-4563-a965-b0063e6cd06c",
   "metadata": {},
   "source": [
    "此处代码将从OBS拷贝数据至开发环境，这段代码需要大家根据井号后面的注释修改拷贝数据集的命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a8bb05-a69b-48f6-a32d-cced9353a731",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\YALOC\\competition.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mox\u001b[39m.\u001b[39mfile\u001b[39m.\u001b[39mcopy_parallel(\u001b[39m'\u001b[39m\u001b[39mobs://swss/data/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m#拷贝数据集的命令，此处的路径需要修改为您自己命名的桶名和路径名。\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#\"swss\"改成自己的桶名，\"swss斜杠后面的data\"改为自己的路径名，第二个data不需要修改。\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mox\u001b[39m.\u001b[39mfile\u001b[39m.\u001b[39mcopy_parallel(\u001b[39m'\u001b[39m\u001b[39mobs://ma-competitions-bj4/keyi/model/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./model/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mox' is not defined"
     ]
    }
   ],
   "source": [
    "mox.file.copy_parallel('obs://swss/data/', './data/')#拷贝数据集的命令，此处的路径需要修改为您自己命名的桶名和路径名。\n",
    "#\"swss\"改成自己的桶名，\"swss斜杠后面的data\"改为自己的路径名，第二个data不需要修改。\n",
    "\n",
    "mox.file.copy_parallel('obs://ma-competitions-bj4/keyi/model/', './model/')#此命令为拷贝模型命令，无须修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7f818-d879-412f-a887-bd6d27fc5c6b",
   "metadata": {},
   "source": [
    "下面的代码将打印数据集的图片数，本次比赛所用数据集共5302张图片，如果下面的代码显示出正确的数字，那么证明你的数据集下载成功了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4902533e-07a3-43bb-b66e-3fd7ef2c1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集图像的数量: 20012\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "images = glob.glob(\"./data/train/*/*\")\n",
    "#print(images)\n",
    "print(f\"数据集图像的数量: {len(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa415c4-01e3-4ca1-b9dd-35eedc1b1fb3",
   "metadata": {},
   "source": [
    "下面的代码将把data中的数据拆分为训练集（train）和测试集（val），此处默认训练集的占比为0.8。运行完成后如果你的路径中出现了上述两个文件夹，那么证明拆分成功了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe81defd-ae45-4e47-90b4-7083b64931e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 训练集的占比\n",
    "train_percent = 0.9\n",
    "# 数据集的目录\n",
    "dataset_dir = \"./data/train\"\n",
    "# 获取类别的名称\n",
    "dir_names = sorted(os.listdir(dataset_dir))\n",
    "splits = [\"train\", \"val\"]\n",
    "for split in splits:\n",
    "    for dir_name in dir_names:\n",
    "        os.makedirs(os.path.join(split, dir_name), exist_ok=True)\n",
    "for dir_name in dir_names:\n",
    "    images = os.listdir(os.path.join(dataset_dir, dir_name))\n",
    "    for index, image in enumerate(images):\n",
    "        if random.random() < train_percent:\n",
    "            split = \"train\"\n",
    "        else:\n",
    "            split = \"val\"\n",
    "        if image==\".ipynb_checkpoints\":\n",
    "            continue\n",
    "        source_path = os.path.join(dataset_dir, dir_name, image)\n",
    "        dist_path = os.path.join(split, dir_name, image)\n",
    "        shutil.copyfile(source_path, dist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57779e57-a85a-4bcb-9b22-0c5cbab80ae7",
   "metadata": {},
   "source": [
    "下面是定义训练方法的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfa4b83-fbf8-471a-8955-1958aeb20f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "from mindspore import Tensor, context, set_seed\n",
    "from mindspore.common import dtype as mstype\n",
    "from mindspore.communication.management import get_group_size, get_rank, init\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.nn.optim.momentum import Momentum\n",
    "from mindspore.train.callback import TimeMonitor, LossMonitor, ModelCheckpoint, CheckpointConfig\n",
    "from mindspore.train.loss_scale_manager import DynamicLossScaleManager, FixedLossScaleManager\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "\n",
    "from model.src.callback import EvaluateCallBack\n",
    "from model.src.config import data_config\n",
    "from model.src.dataset import create_dataset\n",
    "from model.src.loss import CrossEntropySmooth\n",
    "#from model.src.model import ResNet\n",
    "from model.src.image_classification import get_network\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "\n",
    "\n",
    "def get_param_groups(network):\n",
    "    \"\"\" get param groups \"\"\"\n",
    "    decay_params = []\n",
    "    no_decay_params = []\n",
    "    for x in network.trainable_params():\n",
    "        parameter_name = x.name\n",
    "        if parameter_name.endswith('.bias'):\n",
    "            # all bias not using weight decay\n",
    "            no_decay_params.append(x)\n",
    "        elif parameter_name.endswith('.gamma'):\n",
    "            # bn weight bias not using weight decay, be carefully for now x not include BN\n",
    "            no_decay_params.append(x)\n",
    "        elif parameter_name.endswith('.beta'):\n",
    "            # bn weight bias not using weight decay, be carefully for now x not include BN\n",
    "            no_decay_params.append(x)\n",
    "        else:\n",
    "            decay_params.append(x)\n",
    "\n",
    "    return [{'params': no_decay_params, 'weight_decay': 0.0}, {'params': decay_params}]\n",
    "\n",
    "def train_model():\n",
    "    config={\"device_target\":\"CPU\",\"device_id\":0,\"device_num\":1,\"is_distributed\":0}\n",
    "\n",
    "    cfg = data_config\n",
    "    print(cfg.val_data_path)\n",
    "    # set context\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=config[\"device_target\"],)\n",
    "    if config[\"device_target\"] == 'Ascend':\n",
    "        context.set_context(enable_graph_kernel=True)\n",
    "\n",
    "        device_num = int(os.getenv('DEVICE_NUM', '1'))\n",
    "        device_id = int(os.getenv('DEVICE_ID', '0'))\n",
    "\n",
    "        if args_opt.device_id is not None:\n",
    "            context.set_context(device_id=config[\"device_id\"])\n",
    "        else:\n",
    "            context.set_context(device_id=config[\"device_id\"])\n",
    "\n",
    "        if device_num > 1:\n",
    "            context.reset_auto_parallel_context()\n",
    "            context.set_auto_parallel_context(device_num=device_num,\n",
    "                                              parallel_mode=ParallelMode.DATA_PARALLEL,\n",
    "                                              gradients_mean=True)\n",
    "            init()\n",
    "    else:\n",
    "        config[\"device_num\"] = 1\n",
    "        config[\"device_id\"] = 0\n",
    "        if config[\"is_distributed\"]:\n",
    "            init()\n",
    "            device_num = get_group_size()\n",
    "            device_id = get_rank()\n",
    "            context.reset_auto_parallel_context()\n",
    "            context.set_auto_parallel_context(device_num=config[\"device_num\"],\n",
    "                                              parallel_mode=ParallelMode.DATA_PARALLEL,\n",
    "                                              gradients_mean=True)\n",
    "\n",
    "    dataset = create_dataset(cfg.data_path, 1)\n",
    "\n",
    "    batch_num = dataset.get_dataset_size()\n",
    "\n",
    "    #net = ResNet(num_classes=cfg.num_classes)\n",
    "    net = get_network('resnext101',num_classes=cfg.num_classes, platform=cfg.device_target)\n",
    "    # Continue training if set pre_trained to be True\n",
    "    if cfg.pre_trained:\n",
    "        param_dict = load_checkpoint(cfg.checkpoint_path)\n",
    "        load_param_into_net(net, param_dict)\n",
    "\n",
    "    loss_scale_manager = None\n",
    "\n",
    "    if cfg.is_dynamic_loss_scale:\n",
    "        cfg.loss_scale = 1\n",
    "\n",
    "    opt = Momentum(params=get_param_groups(net),\n",
    "                   learning_rate=Tensor(cfg.lr_init, dtype=mstype.float32),\n",
    "                   momentum=cfg.momentum,\n",
    "                   loss_scale=cfg.loss_scale)\n",
    "\n",
    "    loss = CrossEntropySmooth(sparse=True, reduction=\"mean\", num_classes=cfg.num_classes)\n",
    "\n",
    "    if config[\"device_target\"] == 'Ascend':\n",
    "        if cfg.is_dynamic_loss_scale == 1:\n",
    "            loss_scale_manager = DynamicLossScaleManager(init_loss_scale=65536, scale_factor=2, scale_window=2000)\n",
    "        else:\n",
    "            loss_scale_manager = FixedLossScaleManager(cfg.loss_scale, drop_overflow_update=False)\n",
    "    else:\n",
    "        loss_scale_manager = FixedLossScaleManager(cfg.loss_scale, drop_overflow_update=False)\n",
    "\n",
    "    model = Model(net, loss_fn=loss, optimizer=opt, metrics={'acc'},\n",
    "                  amp_level=\"O2\", keep_batchnorm_fp32=True,\n",
    "                  loss_scale_manager=loss_scale_manager)\n",
    "\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=batch_num, keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "    time_cb = TimeMonitor(data_size=batch_num)\n",
    "    ckpt_save_dir = \"./ckpt/\"\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"ResNet\", directory=ckpt_save_dir,\n",
    "                                 config=config_ck)\n",
    "    loss_cb = LossMonitor()\n",
    "    val_dataset = create_dataset(cfg.val_data_path, training=False)\n",
    "    eval_cb = EvaluateCallBack(model=model, eval_dataset=val_dataset)\n",
    "    cbs = [time_cb, ckpoint_cb, loss_cb, eval_cb]\n",
    "    model.train(cfg.epoch_size, dataset, callbacks=cbs, dataset_sink_mode=cfg.use_dataset_sink)\n",
    "    print(\"train success\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79344b02-d367-489c-9c2e-fb5a266f9193",
   "metadata": {},
   "source": [
    "模型训练\n",
    "采用卷积神经网络结构训练模型,模型训练需要一定时间，等待该段代码运行完成后再往下执行,运行完后会保存成生成许多不同轮次的ckpt模型文件，并生成ckpt文件夹，总共有50个epoch，大家需要把所有的轮次运行完了再去跑下面的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e896df-0911-4097-b018-0fac77a01863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./val/\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\YALOC\\competition.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_model()\n",
      "\u001b[1;32mf:\\YALOC\\competition.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m batch_num \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_dataset_size()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m#net = ResNet(num_classes=cfg.num_classes)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m net \u001b[39m=\u001b[39m get_network(\u001b[39m'\u001b[39m\u001b[39mresnext101\u001b[39m\u001b[39m'\u001b[39m,num_classes\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39;49mnum_classes, platform\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdevice_target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Continue training if set pre_trained to be True\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/YALOC/competition.ipynb#X15sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mpre_trained:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e030202-08c1-4f1a-8616-0ecbbd5a9985",
   "metadata": {},
   "source": [
    "下面定义模型测试函数（方法）,用于测试刚刚训练出来的模型的准确率。由于部分同学可能运行了训练脚本多次，checkpoint_path可能需要修改成自己模型的ckpt文件名字，请大家注意检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8965511e-c93b-4211-a487-d8affc15742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process the test set with the .ckpt model in turn.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mindspore import context, Tensor\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common import set_seed\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "\n",
    "from model.src.config import data_config\n",
    "from model.src.model import ResNet\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "device_target=\"CPU\"   #使用显卡来加速进行模型训练\n",
    "checkpoint_path='./ckpt/ResNet-50_125.ckpt'#注意检查此处需改成自己ckpt文件夹下ckpt模型文件的名字\n",
    "\n",
    "def eval():\n",
    "    cfg = data_config\n",
    "    class_indexing = {name: index for index, name in enumerate(sorted(os.listdir(cfg.val_data_path)))}\n",
    "    indexing_class = {index: name for index, name in enumerate(sorted(os.listdir(cfg.val_data_path)))}\n",
    "    images = []\n",
    "    # 存储\n",
    "    for dir_name in os.listdir(cfg.val_data_path):\n",
    "        for class_name in os.listdir(os.path.join(cfg.val_data_path, dir_name)):\n",
    "            images.append([os.path.join(cfg.val_data_path, dir_name, class_name), dir_name])\n",
    "    net = ResNet(cfg.num_classes)\n",
    "    net.set_train(False)\n",
    "\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=device_target)\n",
    "   # context.set_context()#device_id=device_id)\n",
    "    param_dict = load_checkpoint(checkpoint_path)\n",
    "    load_param_into_net(net, param_dict)\n",
    "    num_images = len(images)\n",
    "    correct = 0\n",
    "    mean = np.array([0.5, 0.5, 0.5]).reshape(1, 1, 3)\n",
    "    std = np.array([0.5, 0.5, 0.5]).reshape(1, 1, 3)\n",
    "    for image_path, label in images:\n",
    "        images = Image.open(image_path)\n",
    "        width, height = images.size\n",
    "        left, upper = (width - 224) // 2, (height - 224) // 2\n",
    "        images = images.crop((left, upper, left + 224, upper + 224))\n",
    "        images = np.array(images) / 255  # (224, 224, 3)\n",
    "        images = (images - mean) / std\n",
    "        images = np.transpose(images, (2, 0, 1))\n",
    "        images = Tensor(np.expand_dims(images, 0), dtype=mstype.float32)\n",
    "        result = net(images).asnumpy()\n",
    "        # print(image_path, indexing_class[int(np.argmax(result).reshape(-1))], label)\n",
    "        predict = int(np.argmax(result).reshape(-1))\n",
    "        #print(f\"image_path: {image_path} predict: {indexing_class[predict]} ground_true: {label}\")\n",
    "        if predict == class_indexing[label]:\n",
    "            correct += 1\n",
    "    print(correct)\n",
    "    print(f\"Acc: {correct / num_images * 100}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced9b04-1872-4dff-8c6b-cdd6d7578599",
   "metadata": {},
   "source": [
    "下面运行测试代码，会显示出分类正确模型的个数以及训练好的模型在测试集上的准确率。准确率约为0.6，如果显示出结果证明测试成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d623f4-46c2-4f6f-bd28-653bd57f159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275\n",
      "Acc: 71.79054054054053%\n"
     ]
    }
   ],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fb0ae-e6df-4b72-a5c5-bd66078cb424",
   "metadata": {},
   "source": [
    "将最后一轮训练生成的ckpt模型文件从ckpt文件夹里拷贝出来，准备上传评分。大家仍然要检查一下下面的命名和ckpt文件夹中的是否一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e919cdc-e044-4641-912a-0ec47cff7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy_parallel('./ckpt/train_simple_cnn-50_33.ckpt', './model/train_simple_cnn-50_33.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7129f4-ffe9-4966-a8d6-99572a1fcc47",
   "metadata": {},
   "source": [
    "将训练好的模型导入ModelArts\n",
    "将模型导入ModelArts，为后续推理测试、模型提交做准备。最后显示“所有模型导入完成”证明运行成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8bb265-72a2-407c-a4a0-bcb8375aa182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "\n",
      "Requirement already satisfied: json5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (0.9.8)\n",
      "\n",
      "正在导入模型,模型名称： simple_cnn_476\n",
      "\n",
      "modelarts-cn-north-4-d714a5cc is existed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model/src to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313/model\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model/src to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313/model\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model/src to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313/model\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model/src to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313/model\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model/src to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313/model\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "INFO:obs:Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully upload file /home/ma-user/work/ma_share/competition/model to OBS modelarts-cn-north-4-d714a5cc/model-0708-193313\n",
      "\n",
      "Successfully upload model files from /home/ma-user/work/ma_share/competition/model to obs path /modelarts-cn-north-4-d714a5cc/model-0708-193313.\n",
      "\n",
      "The model source location is https://modelarts-cn-north-4-d714a5cc.obs.cn-north-4.myhuaweicloud.com/model-0708-193313/model\n",
      "\n",
      "publishing\n",
      "\n",
      "published\n",
      "\n",
      "所有模型导入完成\n"
     ]
    }
   ],
   "source": [
    "from modelarts.session import Session\n",
    "from modelarts.model import Model\n",
    "from modelarts.config.model_config import TransformerConfig,Params\n",
    "!pip install json5\n",
    "import json5\n",
    "import re\n",
    "import traceback\n",
    "import random\n",
    "\n",
    "try:\n",
    "    session = Session()\n",
    "    config_path = 'model/config.json' \n",
    "    if mox.file.exists(config_path): # 判断一下是否存在配置文件，如果没有则不能导入模型\n",
    "        model_location =  './model'\n",
    "        model_name = \"simple_cnn\"\n",
    "        load_dict = json5.loads(mox.file.read(config_path))\n",
    "        model_type = load_dict['model_type']\n",
    "        re_name = '_'+str(random.randint(0,1000))\n",
    "        model_name += re_name\n",
    "        runtime=load_dict['runtime']\n",
    "        print(\"正在导入模型,模型名称：\", model_name)\n",
    "        model_instance = Model(\n",
    "                     session, \n",
    "                     model_name=model_name,               # 模型名称\n",
    "                     model_version=\"1.0.0\",               # 模型版本\n",
    "                      source_location_type='LOCAL_SOURCE',\n",
    "                     source_location=model_location,      # 模型文件路径\n",
    "                     model_type=model_type,# 模型类型\n",
    "                     runtime=runtime\n",
    "                     )\n",
    "\n",
    "    print(\"所有模型导入完成\")\n",
    "except Exception as e:\n",
    "    print(\"发生了一些问题，请看下面的报错信息：\") \n",
    "    traceback.print_exc()\n",
    "    print(\"模型导入失败\")"
   ]
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "5e11e51b-456f-4053-8073-8063d3cfb45d"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py_basic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": false,
  "vscode": {
   "interpreter": {
    "hash": "7532d232c29107c34bf01d956d6b351a048317926cdc5b9fc53e3ac5bf53903b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
